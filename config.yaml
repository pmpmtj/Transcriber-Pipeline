# === Model & API ===
model: gpt-4o-transcribe # or gpt-4o-mini-transcribe
response_format: json # json or text
prompt: "" # optional domain hints; keep empty if unsure
parallel_requests: 3
max_retries: 3
backoff_base_ms: 800 # exponential backoff base


# === Chunking policy ===
max_file_mb: 25 # practical upper bound per request; keep conservative
target_chunk_mb: 16 # aim below the hard cap to avoid edge cases
max_chunk_secs: 900 # 15 minutes per chunk max (whichever bound hits first)
overlap_secs: 3.0 # small redundancy to avoid word cuts


# Re-encode each chunk to keep size predictable (recommended)
# For large/variable sources, re-encoding stabilizes chunk sizes.
reencode:
enabled: true
codec: aac # m4a/aac
bitrate_kbps: 64 # 48â€“96 is usually fine for speech
channels: 1
sample_rate: 16000


# === Segmentation strategy ===
segmenter: fixed # fixed | silence


silence:
# Only used if segmenter: silence. Requires ffmpeg silencedetect.
min_silence_db: -35 # threshold (dB)
min_silence_dur: 0.6 # seconds


# === Outputs ===
outputs:
write_txt: true
write_json: true
write_srt: true
write_vtt: false


# === Paths ===
input_audio: "" # set via CLI arg or here
work_dir: "outputs" # artifacts & chunks